PS C:\Users\coolb> & C:/Users/coolb/anaconda3/python.exe c:/Users/coolb/Desktop/SarBERT/Models_RoBERTa_Sentiment.py
Naive Bayes Classification Report:
C:\Users\coolb\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\coolb\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\coolb\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

    negative       0.00      0.00      0.00       381
     neutral       0.81      0.97      0.89     11625
    positive       0.89      0.53      0.67      4861

    accuracy                           0.83     16867
   macro avg       0.57      0.50      0.52     16867
weighted avg       0.82      0.83      0.80     16867

Accuracy: 0.8252208454378372
C:\Users\coolb\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Precision: 0.8164256625424683
Recall: 0.8252208454378372
F1-Score: 0.8024952948847416

Logistic Regression Classification Report:
              precision    recall  f1-score   support

    negative       0.52      0.03      0.05       381
     neutral       0.87      0.96      0.91     11625
    positive       0.87      0.73      0.79      4861

    accuracy                           0.87     16867
   macro avg       0.76      0.57      0.59     16867
weighted avg       0.86      0.87      0.86     16867

Accuracy: 0.8706942550542479
Precision: 0.863330042395442
Recall: 0.8706942550542479
F1-Score: 0.8588154021200617

Linear SVM Classification Report:
              precision    recall  f1-score   support

    negative       0.53      0.02      0.04       381
     neutral       0.87      0.96      0.91     11625
    positive       0.87      0.74      0.80      4861

    accuracy                           0.87     16867
   macro avg       0.76      0.57      0.58     16867
weighted avg       0.87      0.87      0.86     16867

Accuracy: 0.8731250370546036
Precision: 0.8656726424493051
Recall: 0.8731250370546036
F1-Score: 0.861213626657261

Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
C:\Users\coolb\anaconda3\Lib\site-packages\transformers\optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Epoch 1/4
----------
Training BERT: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2460/2460 [12:21<00:00,  3.32it/s] 
Train loss 0.24327150835367903 accuracy 0.9036692585251818
Evaluating BERT: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1055/1055 [01:53<00:00,  9.26it/s]
Val   loss 0.17819281328619585 accuracy 0.9256536432086322

Epoch 2/4
----------
Training BERT: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2460/2460 [12:22<00:00,  3.31it/s] 
Train loss 0.10934836782516942 accuracy 0.9580728769629517
Evaluating BERT: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1055/1055 [01:53<00:00,  9.26it/s]
Val   loss 0.1926946225066303 accuracy 0.92737297681864

Epoch 3/4
----------
Training BERT: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2460/2460 [12:21<00:00,  3.32it/s] 
Train loss 0.054956381576719254 accuracy 0.980383188494181
Evaluating BERT: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1055/1055 [01:54<00:00,  9.25it/s]
Val   loss 0.22440737483634557 accuracy 0.9290923104286476

Epoch 4/4
----------
Training BERT: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2460/2460 [12:21<00:00,  3.32it/s] 
Train loss 0.03685981052940923 accuracy 0.987955481018448
Evaluating BERT: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1055/1055 [01:54<00:00,  9.25it/s]
Val   loss 0.26303110820333964 accuracy 0.9260093674038062

Testing BERT: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1055/1055 [01:43<00:00, 10.15it/s] 
BERT Classification Report:
              precision    recall  f1-score   support

    negative       0.71      0.62      0.66       381
     neutral       0.95      0.94      0.95     11625
    positive       0.88      0.92      0.90      4861

    accuracy                           0.93     16867
   macro avg       0.85      0.82      0.84     16867
weighted avg       0.93      0.93      0.93     16867

Accuracy: 0.9260093674038062
Precision: 0.9261245331031048
Recall: 0.9260093674038062
F1-Score: 0.925857167691147
PS C:\Users\coolb> 